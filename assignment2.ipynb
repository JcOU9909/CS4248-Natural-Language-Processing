{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ca88594-46c7-4d2f-b09e-6e9f76958cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb07e46-4d3e-4d85-87fe-fc10f85ad5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with your Student Number\n",
    "_STUDENT_NUM = 'A0251445J'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcc1732-0032-4a8e-a951-c93043202f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmetize_all(X):\n",
    "    \"\"\" TODO: preprocess data\"\"\"\n",
    "    X_lemmetize = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    for sentence in X:\n",
    "        tmp = []\n",
    "        for word, tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "            if tag.startswith('NN'):\n",
    "                tmp.append(wnl.lemmatize(word, pos='n'))\n",
    "            elif tag.startswith('VB'):\n",
    "                tmp.append(wnl.lemmatize(word, pos='v'))\n",
    "            elif tag.startswith('JJ'):\n",
    "                tmp.append(wnl.lemmatize(word, pos='a'))\n",
    "            elif tag.startswith('R'):\n",
    "                tmp.append(wnl.lemmatize(word, pos='r'))\n",
    "            else:\n",
    "                tmp.append(word)\n",
    "            \n",
    "        X_lemmetize.append(' '.join(tmp))\n",
    "        \n",
    "    return X_lemmetize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a3961d-ec53-41ca-81aa-5189ae4d0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentence_length(X):\n",
    "    return np.array([len(sentence.split()) for sentence in X]).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85d1e89-a9cc-48b9-b3b9-847ecdbf86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polarity(X):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity = []\n",
    "    for sentence in X:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        polarity.append(list(ss.values()))\n",
    "    \n",
    "    return np.array(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfb5997-737c-44ff-9070-c15d43fcc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_num_count(X):\n",
    "    num_count = []\n",
    "    for sentence in X:\n",
    "        count = 0\n",
    "        for _, tag in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "            if tag == 'CD':\n",
    "                count += 1\n",
    "        num_count.append(count)\n",
    "\n",
    "    return np.array(num_count).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3de3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities_by_types(X_train, X_test):\n",
    "    count = []\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    for sentence in X_train:\n",
    "        labels = [x.label_ for x in nlp(sentence).ents]\n",
    "        count.append(Counter(labels))\n",
    "    for sentence in X_test:\n",
    "        labels = [x.label_ for x in nlp(sentence).ents]\n",
    "        count.append(Counter(labels))\n",
    "\n",
    "    return pd.DataFrame(count).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "63acd673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_by_type(df, threshold = 50):\n",
    "    common_list = []\n",
    "    for label in df['Verdict'].unique():\n",
    "        tmp = ' '.join(df.loc[df['Verdict'] == label, 'Text'].values)\n",
    "        tokens = [token.lower() for token in word_tokenize(tmp) if token.isalpha() and \n",
    "                token.lower() not in nltk.corpus.stopwords.words('english')]\n",
    "        common_list.append(FreqDist(tokens).most_common(threshold))\n",
    "\n",
    "    return common_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2ae4f857-6072-447c-842d-42ec09b9b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(df):\n",
    "    ratio = (df['Verdict'] == -1).sum()\n",
    "    for label in [0, 1]:\n",
    "        num = (df['Verdict'] == label).sum()\n",
    "        tmp = df[df['Verdict'] == label].sample(n=3000, replace=True)\n",
    "        df = pd.concat([df, tmp])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe24fe0-b25c-4e4c-a369-cb9fbfcc41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, method = 'nn', need_dev = 'False'):\n",
    "    \"\"\" TODO: train your model based on the training data \"\"\"\n",
    "        \n",
    "    if method == 'nn':\n",
    "        model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "        if need_dev == 'True':\n",
    "            X_train_post, X_dev_post, y_train_post, y_dev_post = train_test_split(\n",
    "                X_train, y_train, test_size=0.2, random_state=42)\n",
    "            history = model.fit(\n",
    "                X_train_post, \n",
    "                y_train_post,\n",
    "                batch_size=512,\n",
    "                epochs=15,\n",
    "                validation_data=(X_dev_post, y_dev_post),\n",
    "            )\n",
    "        else:\n",
    "            history = model.fit(\n",
    "                X_train, \n",
    "                y_train,\n",
    "                batch_size=512,\n",
    "                epochs=15,\n",
    "            )\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4766b3-92b9-4db8-85de-294613757409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test, method = 'nn'):\n",
    "    \"\"\" TODO: make your prediction here \"\"\"\n",
    "    if method == 'nn':\n",
    "        y_pred = np.argmax(model.predict(X_test), axis=1) - 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab714e9-8796-4644-9c29-24c53645da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(test, y_pred, filename):\n",
    "    \"\"\" generate csv file base on the y_pred \"\"\"\n",
    "    test['Verdict'] = pd.Series(y_pred)\n",
    "    test.drop(columns=['Text'], inplace=True)\n",
    "    test.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf993c-be7a-425a-958e-2efb0c7ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" load train, val, and test data \"\"\"\n",
    "    train = pd.read_csv('train.csv')\n",
    "    X_train = train['Text']\n",
    "    y_train = train['Verdict']\n",
    "    \n",
    "    test = pd.read_csv('test.csv')\n",
    "    X_test = test['Text']\n",
    "    # preprocessing\n",
    "    \n",
    "    \n",
    "    model = None  # TODO: Define your model here\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(32, activation='relu', input_shape=(X_train_vec.shape[1],)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # model.summary()\n",
    "    \n",
    "    train_model(model, X_train, y_train)\n",
    "    \n",
    "#     # test your model\n",
    "#     y_pred = predict(model, X_train)\n",
    "\n",
    "    # Use f1-macro as the metric\n",
    "    score = f1_score(y_train, y_pred, average='macro')\n",
    "    print('score on validation = {}'.format(score))\n",
    "\n",
    "    # generate prediction on test data\n",
    "    y_pred = predict(model, X_test)\n",
    "    \n",
    "#     generate_result(test, y_pred, _STUDENT_NUM + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24267b-fff6-4ea1-847b-4554b49ce49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the main class to be invoked if run as a file.\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "93e267b3-a5ac-4250-ac0e-29dccf08281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "# train = over_sampling(train)\n",
    "X_train = train['Text']\n",
    "y_train = train['Verdict']\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "X_test = test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4b5909bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = lemmetize_all(X_train)\n",
    "# X_test = lemmetize_all(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e670df3e-b2cf-4420-a060-74027c37c65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    14685\n",
       " 1     5413\n",
       " 0     2403\n",
       "Name: Verdict, dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e470b-7e46-49af-b986-cb21b97a2fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "75df46f1-078d-487e-9f1a-6e9210ca599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer().fit(X_train)\n",
    "X_train_vec = vectorizer.transform(X_train).toarray()\n",
    "\n",
    "y_train_dum = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "11cb62ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22501, 11424)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8e6ef3f2-3453-4e9d-9575-6f0e537271f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_vec = np.concatenate((X_train_vec, scaler.fit_transform(add_sentence_length(X_train))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c4ce434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = add_polarity(X_train)\n",
    "X_train_vec = np.concatenate((X_train_vec, polarity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8f2caa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_count = add_num_count(X_train)\n",
    "X_train_vec = np.concatenate((X_train_vec, num_count), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e14a9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_list = most_common_by_type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3c6e8083-79dc-4e1b-a018-2fd43f11354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_list = list(set([t[0] for label_common in common_list for t in label_common]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d0ce2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(X_train)\n",
    "word_indices = [vectorizer.vocabulary_[word] for word in extra_list]\n",
    "sub_array = count_matrix[:, word_indices].toarray()\n",
    "\n",
    "X_train_vec = np.concatenate((X_train_vec, sub_array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7c74e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_named_entities_by_types(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "55842b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON</th>\n",
       "      <th>NORP</th>\n",
       "      <th>GPE</th>\n",
       "      <th>ORG</th>\n",
       "      <th>DATE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>LOC</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <th>LAW</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22501 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PERSON  NORP  GPE  ORG  DATE  FAC  CARDINAL  PERCENT  ORDINAL  MONEY  \\\n",
       "0         0.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "1         0.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "2         1.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "3         0.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "4         0.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "...       ...   ...  ...  ...   ...  ...       ...      ...      ...    ...   \n",
       "22496     0.0   0.0  0.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "22497     0.0   1.0  0.0  1.0   0.0  0.0       1.0      0.0      0.0    0.0   \n",
       "22498     0.0   1.0  0.0  1.0   1.0  0.0       0.0      0.0      0.0    0.0   \n",
       "22499     0.0   0.0  2.0  0.0   0.0  0.0       0.0      0.0      0.0    0.0   \n",
       "22500     0.0   0.0  1.0  0.0   1.0  0.0       0.0      0.0      0.0    0.0   \n",
       "\n",
       "       TIME  LOC  WORK_OF_ART  LAW  EVENT  PRODUCT  QUANTITY  LANGUAGE  \n",
       "0       0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "1       0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "2       0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "3       0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "4       0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "...     ...  ...          ...  ...    ...      ...       ...       ...  \n",
       "22496   0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "22497   0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "22498   0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "22499   0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "22500   0.0  0.0          0.0  0.0    0.0      0.0       0.0       0.0  \n",
       "\n",
       "[22501 rows x 18 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:len(X_train_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f501bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = np.concatenate((X_train_vec, data[:len(X_train_vec)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "92a1d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22501, 11535)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c42de79c-7785-40f8-bd73-beecfeb241fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 128)               1476608   \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,485,059\n",
      "Trainable params: 1,485,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(0.001)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, activation='relu', input_shape=(X_train_vec.shape[1],), kernel_regularizer=reg),\n",
    "        # layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=reg),\n",
    "        # layers.Dropout(0.3, seed=1),\n",
    "        layers.Dense(3, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d3585e42-3eac-4838-b5f3-2bc3e213a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "40/40 [==============================] - 2s 35ms/step - loss: 0.9571 - accuracy: 0.6977 - val_loss: 0.7597 - val_accuracy: 0.7343\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6949 - accuracy: 0.7550 - val_loss: 0.6930 - val_accuracy: 0.7517\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.6417 - accuracy: 0.7749 - val_loss: 0.6671 - val_accuracy: 0.7668\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6124 - accuracy: 0.7892 - val_loss: 0.6624 - val_accuracy: 0.7645\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5889 - accuracy: 0.8039 - val_loss: 0.6641 - val_accuracy: 0.7748\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5742 - accuracy: 0.8126 - val_loss: 0.6676 - val_accuracy: 0.7752\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5557 - accuracy: 0.8242 - val_loss: 0.6712 - val_accuracy: 0.7801\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5427 - accuracy: 0.8332 - val_loss: 0.6795 - val_accuracy: 0.7712\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5276 - accuracy: 0.8418 - val_loss: 0.6897 - val_accuracy: 0.7739\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5174 - accuracy: 0.8486 - val_loss: 0.6978 - val_accuracy: 0.7721\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4997 - accuracy: 0.8610 - val_loss: 0.7037 - val_accuracy: 0.7739\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4912 - accuracy: 0.8687 - val_loss: 0.7194 - val_accuracy: 0.7779\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4750 - accuracy: 0.8788 - val_loss: 0.7236 - val_accuracy: 0.7774\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.4616 - accuracy: 0.8881 - val_loss: 0.7473 - val_accuracy: 0.7668\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4518 - accuracy: 0.8938 - val_loss: 0.7530 - val_accuracy: 0.7668\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4389 - accuracy: 0.9013 - val_loss: 0.7650 - val_accuracy: 0.7699\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4274 - accuracy: 0.9104 - val_loss: 0.7801 - val_accuracy: 0.7712\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.4133 - accuracy: 0.9171 - val_loss: 0.7940 - val_accuracy: 0.7699\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4036 - accuracy: 0.9241 - val_loss: 0.7944 - val_accuracy: 0.7681\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3895 - accuracy: 0.9321 - val_loss: 0.8218 - val_accuracy: 0.7610\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.3827 - accuracy: 0.9340 - val_loss: 0.8154 - val_accuracy: 0.7632\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3720 - accuracy: 0.9417 - val_loss: 0.8371 - val_accuracy: 0.7566\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.3613 - accuracy: 0.9466 - val_loss: 0.8488 - val_accuracy: 0.7610\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.3501 - accuracy: 0.9525 - val_loss: 0.8474 - val_accuracy: 0.7668\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.3416 - accuracy: 0.9565 - val_loss: 0.8747 - val_accuracy: 0.7588\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.3343 - accuracy: 0.9592 - val_loss: 0.8793 - val_accuracy: 0.7574\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3255 - accuracy: 0.9621 - val_loss: 0.8729 - val_accuracy: 0.7570\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3188 - accuracy: 0.9659 - val_loss: 0.8832 - val_accuracy: 0.7583\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.3174 - accuracy: 0.9661 - val_loss: 0.9076 - val_accuracy: 0.7459\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.3057 - accuracy: 0.9725 - val_loss: 0.8972 - val_accuracy: 0.7579\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.3010 - accuracy: 0.9722 - val_loss: 0.9091 - val_accuracy: 0.7557\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.2966 - accuracy: 0.9745 - val_loss: 0.9092 - val_accuracy: 0.7534\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.2929 - accuracy: 0.9752 - val_loss: 0.9218 - val_accuracy: 0.7534\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.2835 - accuracy: 0.9787 - val_loss: 0.9231 - val_accuracy: 0.7597\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.2781 - accuracy: 0.9798 - val_loss: 0.9192 - val_accuracy: 0.7526\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.2758 - accuracy: 0.9811 - val_loss: 0.9362 - val_accuracy: 0.7557\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.2717 - accuracy: 0.9827 - val_loss: 0.9358 - val_accuracy: 0.7486\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.2667 - accuracy: 0.9833 - val_loss: 0.9443 - val_accuracy: 0.7539\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.2616 - accuracy: 0.9851 - val_loss: 0.9382 - val_accuracy: 0.7592\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.2605 - accuracy: 0.9838 - val_loss: 0.9401 - val_accuracy: 0.7508\n"
     ]
    }
   ],
   "source": [
    "X_train_post, X_dev_post, y_train_post, y_dev_post = train_test_split(\n",
    "                X_train_vec, y_train_dum, test_size=0.1, random_state=42)\n",
    "history = model.fit(\n",
    "    X_train_post, \n",
    "    y_train_post,\n",
    "    batch_size=512,\n",
    "    epochs=40,\n",
    "    validation_data=(X_dev_post, y_dev_post),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "20b92140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.9601 - accuracy: 0.6897\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.6993 - accuracy: 0.7554\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 1s 19ms/step - loss: 0.6419 - accuracy: 0.7761\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.6091 - accuracy: 0.7930\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.5881 - accuracy: 0.8082\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.5710 - accuracy: 0.8175\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.5560 - accuracy: 0.8242\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.5449 - accuracy: 0.8341\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.5366 - accuracy: 0.8369\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.5263 - accuracy: 0.8469\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_vec, \n",
    "    y_train_dum,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ff380521-1e3f-46ac-86a3-05a82ada8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test = lemmetize_all(X_test)\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test).toarray()\n",
    "X_test_vec = np.concatenate((X_test_vec, scaler.transform(add_sentence_length(X_test))), axis=1)\n",
    "\n",
    "polarity = add_polarity(X_test)\n",
    "X_test_vec = np.concatenate((X_test_vec, polarity), axis=1)\n",
    "\n",
    "num_count = add_num_count(X_test)\n",
    "X_test_vec = np.concatenate((X_test_vec, num_count), axis=1)\n",
    "\n",
    "X_test_vec = np.concatenate((X_test_vec, data[len(X_train_vec):]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "50e9c2a3-0a94-4db6-85c4-8070b1544029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9099069e-01, 2.7621603e-01, 3.2793302e-02],\n",
       "       [6.1257649e-02, 1.3608228e-02, 9.2513406e-01],\n",
       "       [6.6390878e-01, 1.8957989e-01, 1.4651135e-01],\n",
       "       ...,\n",
       "       [9.9561512e-01, 3.4956611e-03, 8.8918046e-04],\n",
       "       [6.6700411e-01, 2.0715892e-01, 1.2583691e-01],\n",
       "       [9.3936062e-01, 4.2241730e-02, 1.8397626e-02]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aea92e39-4eaf-4b37-b12f-ef312494ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_vec), axis=1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "67075b0e-3127-4a29-a9df-b6ee4b862a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "generate_result(test, y_pred, _STUDENT_NUM + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5c4d57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_train_vec)\n",
    "y_dev = np.argmax(y_dev_post.to_numpy(), axis=1) - 1\n",
    "y_dev_pred = np.argmax(model.predict(X_dev_post), axis=1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9654ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.85      0.88      1495\n",
      "           0       0.82      0.88      0.85       551\n",
      "           1       0.79      0.86      0.82       805\n",
      "\n",
      "    accuracy                           0.86      2851\n",
      "   macro avg       0.84      0.86      0.85      2851\n",
      "weighted avg       0.86      0.86      0.86      2851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9ee5e4c9-9080-418d-87c5-1e8a0c94cbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1280,   52,  111],\n",
       "       [ 102,  296,   37],\n",
       "       [ 169,   52,  352]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_dev, y_dev_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e98fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59640504-9d00-408d-ba4a-72bf20f9b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorized_texts = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cf90a-8cdb-4481-b638-527164cf55be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22501x11424 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 335979 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8fab7-24d6-4c9f-96f8-b60ac3a5c471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(vectorized_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fde3c-d35b-4867-99a8-e615dba0a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(vectorized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83ea2a-fd61-4834-bed7-2ea2a9f698b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(y_train, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662eb92a-bcde-44cc-a1c6-95fa7f594c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7175508264672326"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab67664",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0b28f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9c0b16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_texts = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8cf2e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(vectorized_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9def389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514332696324608"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vectorized_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aa5d34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "40cd3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "generate_result(test, y_pred, _STUDENT_NUM + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e46e6b60-64c6-42f3-a690-2e118e2d74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_polarity = collections.defaultdict(list)\n",
    "class_polarity[-1] = [0, 0, 0, 0]\n",
    "class_polarity[0] = [0, 0, 0, 0]\n",
    "class_polarity[1] = [0, 0, 0, 0]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    ss = sid.polarity_scores(X_train[i])\n",
    "    class_polarity[y_train[i]][0] += ss['neg']\n",
    "    class_polarity[y_train[i]][1] += ss['neu']\n",
    "    class_polarity[y_train[i]][2] += ss['pos']\n",
    "    class_polarity[y_train[i]][3] += ss['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2833935c-be81-42ab-85e3-ccb7fe626d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(class_polarity, orient='index').div(y_train.value_counts(), axis=0).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "12dfc256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Storwerqw', 'NN')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"Storwerqw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c7acf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "155276a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8f3abff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22501, 5006)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2752433",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ea40edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96f240e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048283674184939"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4175784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ' '.join(train.loc[train['Verdict'] == -1, 'Text'].values)\n",
    "tokens = [token.lower() for token in word_tokenize(tmp) if token.isalpha() and \n",
    "          token.lower() not in nltk.corpus.stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c008c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9073d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_counts, y_train)\n",
    "y_train_dum2 = pd.get_dummies(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d832053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 128)               1462400   \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,470,851\n",
      "Trainable params: 1,470,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "78/78 [==============================] - 5s 52ms/step - loss: 0.9672 - accuracy: 0.6393 - val_loss: 0.8188 - val_accuracy: 0.7038\n",
      "Epoch 2/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.7648 - accuracy: 0.7280 - val_loss: 0.7660 - val_accuracy: 0.7224\n",
      "Epoch 3/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.6954 - accuracy: 0.7533 - val_loss: 0.7493 - val_accuracy: 0.7272\n",
      "Epoch 4/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.6509 - accuracy: 0.7727 - val_loss: 0.7290 - val_accuracy: 0.7422\n",
      "Epoch 5/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.6145 - accuracy: 0.7951 - val_loss: 0.7252 - val_accuracy: 0.7474\n",
      "Epoch 6/25\n",
      "78/78 [==============================] - 4s 47ms/step - loss: 0.5818 - accuracy: 0.8155 - val_loss: 0.7296 - val_accuracy: 0.7449\n",
      "Epoch 7/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.5468 - accuracy: 0.8368 - val_loss: 0.7411 - val_accuracy: 0.7494\n",
      "Epoch 8/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.5180 - accuracy: 0.8499 - val_loss: 0.7373 - val_accuracy: 0.7544\n",
      "Epoch 9/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.4904 - accuracy: 0.8659 - val_loss: 0.7461 - val_accuracy: 0.7576\n",
      "Epoch 10/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.4667 - accuracy: 0.8800 - val_loss: 0.7525 - val_accuracy: 0.7590\n",
      "Epoch 11/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.4475 - accuracy: 0.8886 - val_loss: 0.7628 - val_accuracy: 0.7612\n",
      "Epoch 12/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.4348 - accuracy: 0.8935 - val_loss: 0.7551 - val_accuracy: 0.7655\n",
      "Epoch 13/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.4213 - accuracy: 0.9001 - val_loss: 0.7604 - val_accuracy: 0.7724\n",
      "Epoch 14/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.4107 - accuracy: 0.9050 - val_loss: 0.7510 - val_accuracy: 0.7678\n",
      "Epoch 15/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.3985 - accuracy: 0.9078 - val_loss: 0.7713 - val_accuracy: 0.7760\n",
      "Epoch 16/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.3912 - accuracy: 0.9107 - val_loss: 0.7752 - val_accuracy: 0.7662\n",
      "Epoch 17/25\n",
      "78/78 [==============================] - 4s 47ms/step - loss: 0.3838 - accuracy: 0.9132 - val_loss: 0.7638 - val_accuracy: 0.7724\n",
      "Epoch 18/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.3774 - accuracy: 0.9156 - val_loss: 0.7625 - val_accuracy: 0.7796\n",
      "Epoch 19/25\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 0.3725 - accuracy: 0.9173 - val_loss: 0.7785 - val_accuracy: 0.7742\n",
      "Epoch 20/25\n",
      "78/78 [==============================] - 4s 53ms/step - loss: 0.3669 - accuracy: 0.9181 - val_loss: 0.7745 - val_accuracy: 0.7746\n",
      "Epoch 21/25\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.3583 - accuracy: 0.9218 - val_loss: 0.7625 - val_accuracy: 0.7762\n",
      "Epoch 22/25\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 0.3519 - accuracy: 0.9242 - val_loss: 0.7678 - val_accuracy: 0.7762\n",
      "Epoch 23/25\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.3499 - accuracy: 0.9247 - val_loss: 0.7915 - val_accuracy: 0.7767\n",
      "Epoch 24/25\n",
      "78/78 [==============================] - 4s 52ms/step - loss: 0.3505 - accuracy: 0.9233 - val_loss: 0.7926 - val_accuracy: 0.7769\n",
      "Epoch 25/25\n",
      "78/78 [==============================] - 4s 57ms/step - loss: 0.3409 - accuracy: 0.9278 - val_loss: 0.7789 - val_accuracy: 0.7794\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(0.001)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, activation='relu', input_shape=(X_train_resampled.shape[1],), kernel_regularizer=reg),\n",
    "        # layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=reg),\n",
    "        # layers.Dropout(0.3, seed=1),\n",
    "        layers.Dense(3, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "X_train_post, X_dev_post, y_train_post, y_dev_post = train_test_split(\n",
    "                X_train_resampled.toarray(), y_train_dum2, test_size=0.1, random_state=42)\n",
    "history = model.fit(\n",
    "    X_train_post, \n",
    "    y_train_post,\n",
    "    batch_size=512,\n",
    "    epochs=25,\n",
    "    validation_data=(X_dev_post, y_dev_post),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e77f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e7e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1e31f704b02f36dd9211742a29ae85dddc2da720b4ac32804e8ae51264cf558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
